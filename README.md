[【👉官网入口，点击这里进入】](https://zzgcz.com)~



深度学习实战项目代码，模型论文笔记，视频课程


# 深度学习模型笔记

深度学习100例、深度学习DL、图片分类、目标识别、目标检测、自然语言处理nlp、文本分类、TensorFlow、PyTorch


- [LeNet-5：手写数字识别经典CNN](https://gc4v29mfja.feishu.cn/wiki/KAmuwR2k3iDIfgkd7uDcY5Z1n3g)
- [AlexNet：ImageNet革命性突破](https://gc4v29mfja.feishu.cn/wiki/LwrTwEPCGikGMEkpJ5lcVRlTnxb)
- [VGGNet：深而简单的结构](https://gc4v29mfja.feishu.cn/wiki/A0R5wwQ4wit8TrknjoQc1bBcn6D)
- [GoogLeNet (Inception v1) ：Inception模块引入](https://gc4v29mfja.feishu.cn/wiki/SAPdwzsSsiUsHvkt9HmcbueGnZA)
- [Network in Network (NIN)：1×1卷积首次提出](https://gc4v29mfja.feishu.cn/wiki/D3ucwBh1Ni0bhFkd82xcyrpknKh)
- [Inception v2/v3：多尺度创新](https://gc4v29mfja.feishu.cn/wiki/KOQJwHAIrigYSgk3tZUcoGRrngk)
- [ResNet：残差结构革命](https://gc4v29mfja.feishu.cn/wiki/LbMiwXpcMieTCgkhXAwcBTFZnHb)
- [ResNeXt：分组卷积](https://gc4v29mfja.feishu.cn/wiki/GBmdwLP6gi1Vx9koMgAckykwn7c)
- [DenseNet：密集连接](https://gc4v29mfja.feishu.cn/wiki/C1EnwfAyDizMLWkLy5acXYxynUb)
- [SqueezeNet：极小参数量](https://gc4v29mfja.feishu.cn/wiki/Klnewaj4EiXk7ikN8ytcz0mmnVe)
- [Xception：深度可分离卷积](https://gc4v29mfja.feishu.cn/wiki/F0cHwXvVlidPrUkMmanczu87nz4)
- [MobileNet v1：轻量化卷积](https://gc4v29mfja.feishu.cn/wiki/S2WWwyL1FiUa6CkgWWlcmx2Wnyg)
- [ShuffleNet v1：高效组卷积](https://gc4v29mfja.feishu.cn/wiki/BuWdw2IWbievIkknXKEcqHdNngd)
- [SENet：通道注意力](https://gc4v29mfja.feishu.cn/wiki/I3ouwooS6ieogRkRpejcdKcDnNh)
- [MobileNet v2：倒残差结构](https://gc4v29mfja.feishu.cn/wiki/E3yewHzhgiPdgAkL0l7cmL3ynoc)
- [ShuffleNet v2：改进轻量化结构](https://gc4v29mfja.feishu.cn/wiki/XROiwNDGwi66TjkM0qZczecnn9b)
- [MnasNet：NAS 自动架构搜索](https://gc4v29mfja.feishu.cn/wiki/OlAPwZmwFiJCCHkgpHvcsR9mned)
- [EfficientNet：复合缩放](https://gc4v29mfja.feishu.cn/wiki/WEuCwYLctiz3BIkp9Vyc1ihSnlh)
- [RegNet：高效可扩展网络](https://gc4v29mfja.feishu.cn/wiki/AWYHwQbXRiIF71kDNqBcYUXKnNf)
- [Vision Transformer (ViT)：Transformer引入视觉](https://gc4v29mfja.feishu.cn/wiki/AOGVwH3OkiCisNkOd7JcECYlnib)
- [DeiT：数据高效ViT](https://gc4v29mfja.feishu.cn/wiki/WzbVwo9ZQiw9r2kvZrmc2ZU5nHh)
- [PVT（Pyramid Vision Transformer）：金字塔结构，适合检测/分割](https://gc4v29mfja.feishu.cn/wiki/G1XIwRh3WiK5ZHkQcFGcyER8nHg)
- [Swin Transformer：分层局部注意力](https://gc4v29mfja.feishu.cn/wiki/NbwIw47LViYddWkJDVtcH6mKnWe)
- [R-CNN：两阶段检测开山](https://gc4v29mfja.feishu.cn/wiki/CHI5wSCoCifZU4kLXK8ccTfDnVc)
- [Fast R-CNN：ROI Pooling](https://gc4v29mfja.feishu.cn/wiki/SlWew0tGgiM0Dhk8R5zcN4pBnae)
- [Faster R-CNN：RPN引入](https://gc4v29mfja.feishu.cn/wiki/AzujwLo3uiNYlLkYOTycHrbbn2f)
- [YOLO v1：单阶段实时检测](https://gc4v29mfja.feishu.cn/wiki/DKlmwdKebiGWKjkuDSmchlSUnrc)
- [SSD：多尺度检测](https://gc4v29mfja.feishu.cn/wiki/RAGAwPQSdi3PmDkhkLfcA3xFnTc)
- [YOLO v2：Anchor机制](https://gc4v29mfja.feishu.cn/wiki/JADKwk8YgiPVpYkzGZjcQ5CTnMd)
- [RetinaNet：Focal Loss焦点损失](https://gc4v29mfja.feishu.cn/wiki/C4fmwCroziNnldkeDr0cQ54Hn8b)
- [YOLO v3：多尺度预测](https://gc4v29mfja.feishu.cn/wiki/H7UXwx3yuikv20kT8Arc4iJhngf)
- [EfficientDet：EfficientNet主干检测](https://gc4v29mfja.feishu.cn/wiki/Cf7VwjohNiSCRpkEfG1cYqecnkb)
- [CoAtNet：CNN+Transformer融合](https://gc4v29mfja.feishu.cn/wiki/TeZpwlHqmiOHV5kOVUccLmmknLh)
- [YOLOv4：高速高精度检测](https://gc4v29mfja.feishu.cn/wiki/D7YowGXKniFFbDkTqzWcxSS4nYO)
- [DETR ：Transformer 检测开山之作](https://gc4v29mfja.feishu.cn/wiki/QuUewidfJiDofvkIibTc225qnid)
- [Deformable DETR：加速收敛，关键改进版](https://gc4v29mfja.feishu.cn/wiki/KLK3w7O1jirVuWky1RocZ5TCnYe)
- [YOLOX：Anchor-Free检测](https://gc4v29mfja.feishu.cn/wiki/HTdewPcmciVRLNk6RS9crCNnnGo)
- [Sparse R-CNN：稀疏候选框，Query-based 思路](https://gc4v29mfja.feishu.cn/wiki/BEYnwHJIXiu87QkhhAScZVlHnPY)
- [YOLOv7：高性能检测](https://gc4v29mfja.feishu.cn/wiki/LAU5wDwnQiQApbkejficIeFHnHd)
- [RT-DETR：实时DETR检测](https://gc4v29mfja.feishu.cn/wiki/IJRMwO7bpiy7GckAUdTcKD01n2c)
- [DINO ：改进版 DETR，学术界基线](https://gc4v29mfja.feishu.cn/wiki/WVV3wGONgiGIW6kMot0cWccAnyh)
- [FCN ：语义分割开山作](https://gc4v29mfja.feishu.cn/wiki/DSRYw94b8imwFzknqY2cFsOJnwa)
- [U-Net：医学分割经典](https://gc4v29mfja.feishu.cn/wiki/ToBsw4PQIil8usk5wqYc15binkg)
- [SegNet ：索引反池化的轻量分割网络](https://gc4v29mfja.feishu.cn/wiki/DGsAwc7JqiJ6tGkkdb9czQuLngg)
- [V-Net：三维医学影像分割](https://gc4v29mfja.feishu.cn/wiki/GxOMwG9i7iRj8Ek6uvScBy6rnLf)
- [PSPNet ：金字塔池化](https://gc4v29mfja.feishu.cn/wiki/YLLtw8ljlieuU2ksAphckQ01nbh)
- [Mask R-CNN：实例分割基线](https://gc4v29mfja.feishu.cn/wiki/IR6HwgeApigS8jkjVoFckr2CnOe)
- [DeepLab v3+：空洞卷积改进](https://gc4v29mfja.feishu.cn/wiki/WmTuwtmQti6q1ekehdFcXm0anSg)
- [Attention U-Net：引入注意力门机制](https://gc4v29mfja.feishu.cn/wiki/GlAbwOB8iialKUkZcDpc5NP7n6e)
- [ResUNet：U-Net 中加入残差块](https://gc4v29mfja.feishu.cn/wiki/NQiEwcFmniwJBJk4JMVcMbFlnRe)
- [U-Net++：嵌套密集跳跃连接，多尺度融合增强特征表达](https://gc4v29mfja.feishu.cn/wiki/ETCLw8rUWi2Ur5k4FoBcBS0nnUb)
- [Monodepth：无监督单目深度估计：基于视图重构的自学习](https://gc4v29mfja.feishu.cn/wiki/EtW1whIzlijorhk3LSccKA3onha)
- [Monodepth2：自监督单目深度估计的改进](https://gc4v29mfja.feishu.cn/wiki/J9vzwRStoiGRQnkI2O5cWas4nJd)
- [MiDaS：零样本泛化能力”极强，广泛用作预训练 backbone](https://gc4v29mfja.feishu.cn/wiki/LWYowsc18iryWVksfF9caYi0nYg)
- [DPT ：Vision Transformer 革新密集深度预测](https://gc4v29mfja.feishu.cn/wiki/W2f9wObaZiSSzrkfui6cUgJDnWf)
- [Depth Anything：通用深度估计大模型](https://gc4v29mfja.feishu.cn/wiki/E75SwsZ4ziJ4Gtk6VjecDwwInhe)
- [GCNet ：端到端双目深度：3D卷积代价体积聚合](https://gc4v29mfja.feishu.cn/wiki/DknUwKIVpiZplCkom0VcT7YJngg)
- [PSMNet：空间金字塔池化赋能立体匹配](https://gc4v29mfja.feishu.cn/wiki/UO23wDApuiy0dtkhJ2XcGJFhnGW)
- [GANet：可导引导聚合：替代3D卷积的立体匹配新思路](https://gc4v29mfja.feishu.cn/wiki/JE8XwFpLwi1VXHkEIxRcVV2nn6b)
- [MVSNet ：第一个端到端深度学习 MVS](https://gc4v29mfja.feishu.cn/wiki/KSeLwbbW4ibzQbkfgtncXsWbnUh)
- [CasMVSNet ：级联思想，后续大部分方法的原型](https://gc4v29mfja.feishu.cn/wiki/DV5TwHkKeiTnkOkBZnrc0MwdnOd)
- [PatchmatchNet ：学习化 PatchMatch，效率里程碑。](https://gc4v29mfja.feishu.cn/wiki/KzQRwoiRCimQzckyfgbcCdZynve)
- [TransMVSNet ：Transformer 在 MVS 的应用](https://gc4v29mfja.feishu.cn/wiki/PWLUw7oJCidfjKkyJ9UcAl6OnZb)
- [MVSAnywhere：现阶段的终点，零样本泛化方向](https://gc4v29mfja.feishu.cn/wiki/XGQYwME1KiUTZUkVdooceaI7npd)
